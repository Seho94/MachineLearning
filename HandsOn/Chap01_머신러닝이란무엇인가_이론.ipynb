{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2ab349",
   "metadata": {},
   "source": [
    "## 1.1 머신러닝이란?\n",
    "  \n",
    "  데이터에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학(혹은 예술)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4307e1",
   "metadata": {},
   "source": [
    "## 1.2 왜 머신러닝을 사용하는가?\n",
    "  \n",
    "  전통적인 프로그래밍 방식에서 한계점을 통해 도출한 의문들\n",
    "  1. 패턴을 자동으로 추출할 수 있다면?\n",
    "  2. 추세의 변화를 반영한다면?\n",
    "  3. 문제 해결 방법을 스스로 찾을 수 있다면?\n",
    "  4. 대용량의 데이터 분석이 가능하다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa3eb0c",
   "metadata": {},
   "source": [
    "## 1.3 애플리케이션 사례\n",
    "  \n",
    "  데이터마이닝이란? 머신러닝 기술을 적용해서 대용량의 데이터를 분석하여 패턴을 추출해 내는 과정!\n",
    "  \n",
    "  1. Text\n",
    "      - 자동으로 뉴스 기사 분류 >> >> NLP, RNN, 트랜스포머 등\n",
    "      - 문서 자동 요약 >> NLP, RNN, 트랜스포머 등\n",
    "  2. Image\n",
    "      - 반도체 Defect여부 및 타입 분류 >> CNN\n",
    "      - 뇌 스캔하여 종양 진단 >> CNN\n",
    "  3. Number\n",
    "      - 비트코인 가격 예측 >> Regressor - RFR, XGBoost, LSTM 등\n",
    "      - 스마트폰 수요 예측 >> Regressor - RFR, XGBoost, LSTM 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f91738",
   "metadata": {},
   "source": [
    "## 1.4 머신러닝 시스템의 종류\n",
    "  \n",
    "  머신러닝 알고리즘은 굉장히 많다. '어떤 알고리즘'을 '어떤 기준'으로 선택할 수 있을까?\n",
    "  \n",
    "  1. 훈련감독방법\n",
    "      - 지도학습: 정답이 있는 경우 >> 분류, 회귀\n",
    "          - 대표 알고리즘\n",
    "              1. KNN\n",
    "              2. 로지스틱회귀\n",
    "              3. SVM\n",
    "              4. 결정트리\n",
    "              5. 랜덤포레스트 등\n",
    "      - 비지도학습: 정답이 없는 경우 >> 군집, 차원 축소, 이상치 탐지\n",
    "          - 대표 알고리즘\n",
    "              1. K-Means\n",
    "              2. PCA\n",
    "              3. t-SNE\n",
    "              4. DBSCAN\n",
    "              5. Auto-Encoder 등\n",
    "      - 준지도학습: 정답이 일부만 있는 경우 (지도+비지도 조합)\n",
    "      - 강화학습: 행동에 보상이 있는 경우 >> 투자, 게임(전략이 필요할 때)\n",
    "  2. 훈련 시점\n",
    "      - 배치학습 (오프라인 학습)\n",
    "          - 가용한 '모든 데이터'를 사용하여 오프라인에서 학습\n",
    "          - 데이터 추가 시 전체 데이터를 다시 학습 >> 이전 모델 삭제 후 교체 (Ver별 백업파일 보관 필수)\n",
    "          - 데이터 Trend 변화를 빠르게 Catch up 해야 하는 데이터에는 부적합 (ex. 주식)\n",
    "          - 컴퓨팅 자원이 풍부한 경우 사용\n",
    "      - 온라인학습\n",
    "          - 적은 데이터(미니 배치 단위)를 사용해 점진적으로 학습\n",
    "          - 학습이 끝난 데이터는 (재사용해야하는 이유가 없다면) 버려도 됨\n",
    "          - 데이터 Trend 변화를 실시간으로 Catch up 가능 >> but, 비정상 데이터 주입 시 성능 저하\n",
    "          - 컴퓨팅 자원이 제한된 경우 사용\n",
    "  3. 모델 생성 (어떻게 일반화하는가?)\n",
    "      - 사례 기반 학습\n",
    "          - 훈련 샘플을 기억하여 Training\n",
    "          - 예측을 위해 샘플 사이의 유사도 측정\n",
    "      - 모델 기반 학습\n",
    "          - 샘플로 Train하여 모델을 생성\n",
    "          - 훈련된 모델로 새로운 샘플을 예측\n",
    "          \n",
    "  * 머신러닝 프로젝트 Flow\n",
    "      1. 데이터를 분석한다.\n",
    "          - Scatter Plot, Box Plot 등을 통해 데이터의 모양을 관찰한다.\n",
    "      2. 모델을 선택한다.\n",
    "          - 앞의 3가지 기준을 고려하여 데이터에 적합한 후보 모델을 선택한다.\n",
    "      3. 훈련 데이터로 모델을 훈련시킨다.\n",
    "          - Train Data를 이용하여 효용 함수를 최대화하거나, 비용 함수를 최소화할 수 있는 Parameter를 학습한다.\n",
    "      4. 새로운 데이터에 모델을 적용해 예측을 하고, 이 모델이 일반화되길 기대한다.\n",
    "          - 훈련 시 모델이 한번도 보지 않은 데이터를 활용하여 성능을 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c700cf",
   "metadata": {},
   "source": [
    "## 1.5 머신러닝의 주요 도전 과제\n",
    "  \n",
    "  1. Bad Data\n",
    "      - 충분하지 않은 양의 훈련 데이터: 간단한 문제라도 수천 개의 데이터 필요!\n",
    "      - 대표성 없는 훈련 데이터: 샘플이 작으면 샘플링 Noise가 생기고, 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못한다. (Sampling Bias)\n",
    "      - 낮은 품질의 데이터: 이상치, 결측치, 에러값을 정제하는데에 가장 많은 시간이 소요된다.\n",
    "      \n",
    "  2. Bad Algorithm\n",
    "      - 관련 없는 특성: Feature Selection과 Feature Extraction을 통해 문제에 관련이 높은 특성만 사용하자.\n",
    "      - 훈련 데이터 과대 적합: 훈련 세트에 너무 잘 맞아 일반화 성능이 낮은 문제\n",
    "          - 해결방법\n",
    "              1. Parameter 수를 적게 하거나, 모델에 제약을 가하여 단순화\n",
    "              2. 훈련 데이터를 더 많이 모은다.\n",
    "              3. 훈련 데이터의 잡음을 줄인다. (오류 데이터 수정 및 이상치 제거)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acdd60b",
   "metadata": {},
   "source": [
    "## 1.6 테스트와 검증\n",
    "   1. Train / Test set 분할\n",
    "   2. Train셋을 Tran과 Validaiton 셋으로 분할\n",
    "   3. Train셋을 활용한 Train 모델 학습\n",
    "   4. Validation을 활용한 모델 Test\n",
    "       - 성능이 나쁘다면 3단계로 돌아가자\n",
    "   5. Test셋을 활용한 실제 테스트!\n",
    "     \n",
    "### 데이터 분석 모형 검증 방법\n",
    "   1. 홀드아웃\n",
    "       - Train / Test을 비복원 추출 방법을 이용하여 (랜덤하게) Train set과 Validation set으로 나눠 검증하는 기법\n",
    "   2. 다중 교차 검증 (ex. K-Fold 교차 검증)\n",
    "       - 데이터 집합을 무작위로 동일 크기를 갖는 K개의 부분집합으로 나누고, 1개를 Validation set으로, 나머지 K-1개를 Train set으로 선정하여 분석 모형을 평가하는 방법\n",
    "       - 모든 모델의 평가를 평균하면 좀 더 정확한 성능을 측정할 수 있지만, Train 시간이 늘어난다는 단점이 있다.\n",
    "       - 만약 K 갯수가 데이터의 길이 N과 동일하다면 LOOCV (Leave-One-Out Cross Validation)\n",
    "           - 데이터가 작을 경우, 활용한다.\n",
    "           \n",
    "  * Train Set과 Test Set의 특징은 일치해야 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
